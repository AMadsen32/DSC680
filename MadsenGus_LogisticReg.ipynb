{"cells":[{"cell_type":"code","source":["%python\n%md\n\n## Overview\n\nThis notebook will show you how to create and query a table or DataFrame that you uploaded to DBFS. [DBFS](https://docs.databricks.com/user-guide/dbfs-databricks-file-system.html) is a Databricks File System that allows you to store data for querying inside of Databricks. This notebook assumes that you have a file already inside of DBFS that you would like to read from.\n\nThis notebook is written in **Python** so the default cell type is Python. However, you can use different languages by using the `%LANGUAGE` syntax. Python, Scala, SQL, and R are all supported."],"metadata":{},"outputs":[],"execution_count":1},{"cell_type":"code","source":["%python\n# File location and type\nfile_location = \"/FileStore/tables/baby_names-b9fc6.csv\"\nfile_type = \"csv\"\n\n# CSV options\ninfer_schema = \"false\"\nfirst_row_is_header = \"false\"\ndelimiter = \",\"\n\n# The applied options are for CSV files. For other file types, these will be ignored.\ndf = spark.read.format(file_type) \\\n  .option(\"inferSchema\", infer_schema) \\\n  .option(\"header\", first_row_is_header) \\\n  .option(\"sep\", delimiter) \\\n  .load(file_location)\n\ndisplay(df)"],"metadata":{},"outputs":[],"execution_count":2},{"cell_type":"code","source":["%python\n# Create a view or table\n\ntemp_table_name = \"baby_names-b9fc6_csv\"\n\ndf.createOrReplaceTempView(temp_table_name)"],"metadata":{},"outputs":[],"execution_count":3},{"cell_type":"code","source":["%sql\n\n/* Query the created temp table in a SQL cell */\n\nselect * from `baby_names-b9fc6_csv`"],"metadata":{},"outputs":[],"execution_count":4},{"cell_type":"code","source":["%python\n# With this registered as a temp view, it will only be available to this particular notebook. If you'd like other users to be able to query this table, you can also create a table from the DataFrame.\n# Once saved, this table will persist across cluster restarts as well as allow various users across different notebooks to query this data.\n# To do so, choose your table name and uncomment the bottom line.\n\npermanent_table_name = \"baby_names-b9fc6_csv\"\n\n# df.write.format(\"parquet\").saveAsTable(permanent_table_name)"],"metadata":{},"outputs":[],"execution_count":5},{"cell_type":"code","source":["%sql\nfrom pyspark.ml.classification import LogisticRegression\n\n# Create initial LogisticRegression model\nlr = LogisticRegression(labelCol=\"label\", featuresCol=\"features\", maxIter=10)\n\n# Train model with Training Data\nlrModel = lr.fit(trainingData)"],"metadata":{},"outputs":[],"execution_count":6},{"cell_type":"code","source":["%sql\npredictions = lrModel.transform(testData)"],"metadata":{},"outputs":[],"execution_count":7},{"cell_type":"code","source":["%sql\nselected = predictions.select(\"label\", \"prediction\", \"probability\", \"age\", \"name\", \"state\")\ndisplay(selected)"],"metadata":{},"outputs":[],"execution_count":8},{"cell_type":"code","source":["%sql\n\nfrom pyspark.ml.evaluation import BinaryClassificationEvaluator\n\n# Evaluate model\nevaluator = BinaryClassificationEvaluator(rawPredictionCol=\"rawPrediction\")\nevaluator.evaluate(predictions)"],"metadata":{},"outputs":[],"execution_count":9},{"cell_type":"code","source":["%sql\nevaluator.getMetricName()"],"metadata":{},"outputs":[],"execution_count":10},{"cell_type":"code","source":["%sql\nweights = cvModel.bestModel.coefficients\nweights = [(float(w),) for w in weights] \nweightsDF = sqlContext.createDataFrame(weights, [\"Feature Weight\"])\ndisplay(weightsDF)"],"metadata":{},"outputs":[],"execution_count":11},{"cell_type":"code","source":["%sql\nselected = predictions.select(\"label\", \"prediction\", \"probability\", \"age\", \"name\", \"state\")\ndisplay(selected)"],"metadata":{},"outputs":[],"execution_count":12},{"cell_type":"code","source":["%sql\n\nval lr = new LogisticRegression()\n  .setMaxIter(10)\n  .setRegParam(0.3)\n  .setElasticNetParam(0.8)"],"metadata":{},"outputs":[],"execution_count":13},{"cell_type":"code","source":["%sql\nval lrModel = lr.fit(training)\nprintln(s\"Coefficients: ${lrModel.coefficients} Intercept: ${lrModel.intercept}\")"],"metadata":{},"outputs":[],"execution_count":14},{"cell_type":"code","source":["%sql\nval mlr = new LogisticRegression()\n  .setMaxIter(10)\n  .setRegParam(0.3)\n  .setElasticNetParam(0.8)\n  .setFamily(\"multinomial\")"],"metadata":{},"outputs":[],"execution_count":15},{"cell_type":"code","source":["%sql\nimport matplotlib.pyplot as plt\nplt.figure(figsize=(5,5))\nplt.plot([0, 1], [0, 1], 'r--')\nplt.plot(babynames.summary.roc.select('FPR').collect(),\n         babynames.summary.roc.select('TPR').collect())\nplt.xlabel('FPR')\nplt.ylabel('TPR')\nplt.show()"],"metadata":{},"outputs":[],"execution_count":16}],"metadata":{"name":"MadsenGus_LogisticReg","notebookId":3108468742624100},"nbformat":4,"nbformat_minor":0}
